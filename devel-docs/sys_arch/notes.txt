Заметки по архитектуре системы KEDR
-----------------------------------

Здесь собраны некоторые идеи, которые могут быть, а могут и не быть 
реализованы в системе KEDR.
=======================================================================

1. Распределение компонентов системы по модулям ядра

1.1
Удобно Loading Detector и Call Instrumentation Facilities держать вместе в 
одном модуле ядра ("Controller module").

При загрузке этого модуля ему передаётся параметр - имя анализируемого 
(target) модуля, того, момент загрузки которого надо отследить и который 
надо инструментировать.

1.2
Call Monitor, Base Checker, Fault Simulator (т.н. "payload-модули", 
"полезная нагрузка") лучше оформить как отдельные ("сменные") модули ядра. 
На данном этапе предполагается, что в каждый момент времени может быть 
загружен один или несколько из них. А может быть так, что и никто из них не 
загружен.

Никакой из одновременно находящихся в памяти payload-модулей не должен 
требовать перехвата функций, которые нужно перехватывать другим 
payload-модулям. Т.е. множества функций, вызовы которых будут подменяться 
на вызовы replacement функций из каждого payload module, не должны 
пересекаться. Пока считаем, что в противном случае behaviour is undefined в 
плане того, какие именно результаты будут выданы пользователю. Т.е. не 
определено, какая из конфликтующих replacement-функций будет вызываться, но 
какая-то будет (ровно одна из них). Тем не менее, модули KEDR не должны 
падать и в таком случае, работа с остальными replacement-функциями не 
должна пострадать.

От каждого payload-модуля требуется предоставить controller-модулю 
таблицу замены адресов функций, которую тот будет использовать. 

[NB] Поиск адресов экспортируемых функций по имени (в строковом виде) 
разработчиками ядра очень не приветствуется. kallsyms_lookup_* не везде 
экспортируется, а symbol_get / symbol_put не везде работают и, возможно, в 
след. версиях ядра будут заменены пустышками (если это ещё не сделано), 
судя по обсуждениям в LKML. 

Рекомендуемый разработчиками ядра вариант таков (см., например, crypto 
framework). 

Controller module хранит список загруженных payload modules и экспортирует 
функции для регистрации / дерегистрации payload module (что-то вроде 
kedr_payload_register & kedr_payload_unregister).

Каждый payload module в конце своей init-функции вызывает 
kedr_payload_register(), а где-то в начале cleanup-функции - 
kedr_payload_unregister().

В каждый из этих двух вызовов передаётся указатель на структуру (struct 
kedr_payload ???), содержащую, как минимум, указатель на соотв. struct 
module, а также содержащую таблицу замены адресов функций.

Когда controller выявит момент загрузки target module, он производит 
подмену адресов вызовов в соответствии с таблицами замен всех 
зарегистрированных payload module. 

[NB] Когда controller проводит инструментирование / деинструментирование 
target module, можно при этом вызывать что-то вроде try_module_get() для 
каждого из зарегистрированных payload modules, чтобы их нельзя было 
выгрузить, пока идёт процесс. Когда инструментирование завершено, можно 
делать module_put. 

Если payload module выгружается и вызывает kedr_payload_unregister(), 
controller должен провести деинструментирование: в соотв. с таблицей замен 
адресов для данного payload module вернуть исходные адреса вызовов вместо 
подменённых. 

Сам controller нельзя выгрузить, пока загружен хоть один payload module: 
ядро не даст, т.к. payload module используют символы из controller module.

[NB] Нужно обеспечить, чтобы в код инструментирования с controller module 
не было одновременных вхождений (мало ли - два payload module одновременно 
выгружаются и т.п.). Mutex подойдёт.

При такой схеме работы controller module не зависит от того, что 
конкретно делает payload module и какие конкретно функции ему нужно 
перехватывать. Для одних типов проверок нужно отслеживать одни вызовы, для 
других - другие.

Less coupling + reusable parts => good extendable system 

Кстати, это позволит решать вопрос с copy_from_user / _copy_from_user, не 
затрагивая при этои controller module. Например, это можно делать на 
стадии конфигурации и сборки соотв. payload module (плюс, вероятно, #ifdef 
HAVE_COPY_FROM_USER ...).

1.3
Самая важная часть каждого payload module - набор replacement фунций и, 
если есть, набор соотв. trace events для вывода информации из этих функций.

1.4
В controller module стоит при обработке загрузки target module 
сохранить указатель на соотв. struct module* (NULL, если в данный момент  
target модуль ещё не загружен или уже выгружен). Вероятно, стоит ещё 
экспортировать функцию, которая выдаёт этот указатель (условно назовём её 
kedr_target_module_ptr() ). 

Это может пригодиться payload-модулям (например, для проверки module state, 
чтобы выяснить, выполняется init или уже основная часть модуля).

1.5
Надо ли делать preempt_disable на время инструментирования target module? 
Возможно, это стоит сделать, чтобы никто процессу не мешал...
=======================================================================

2. Fault simulation

2.1
Нужен API для приложений пользовательского режима для загрузки (и смены) 
сценария fault simulation в runtime. Как конкретно этот сценарий будет 
передан в соотв. payload module - это проблема реализации API. Будет ли 
использоваться запись в соотв. устройство, или ioctl для этого устройства, 
или netlink, или что-то ещё - для пользователя это неважно и ему не стоит 
рассчитывать, что будет использован какой-то конкретный механизм передачи 
данных.

Возможность изменения сценария в runtime полезна для тестов, в который 
сначала соотв. запросами (напр., из user space) target module приводится в 
нужное состояние, а затем уже нужно применять fault simulation, чтобы 
проверить соотв. пути в коде target module.

2.2
Вероятно, стоит предусмотреть задание для каждой из функций, интересующих 
разработчика, своего сценария fault simulation.

2.3
Стоит предусмотреть, как минимум, такие виды сценариев: 
- fail all calls
- fail all calls after init

Полезно иметь возможность задавать и другие сценарии.

2.4
Технически, в качестве "сценария" fault simulation для целевой функции 
можно задавать номер (индекс) некоторой функции-индикатора в списке таковых 
для этой функции. Функция-индикатор принимает заранее оговорённые 
параметры и возвращает что-то вроде true/false (не ноль / ноль ?).

[NB] При таком подходе придётся держать внутри payload module все 
функции-индикаторы для различных вариантов fault simulation. Из других 
модулей их не возьмёшь. Нужны нестандартные сценарии fault simulation - 
нужен новый payload module. Пусть пока будет так. В дальнейшем, возможно, 
это ограничение удастся обойти - если это будет критично.

[NB] М.б., было бы удобнее, если бы можно было задавать не индекс, а имя и 
по нему искать адрес соотв. функции. Но, увы, в ядре поиск адресов символов 
по именам очень не приветствуется (для модулей, но не для собственно ядра) 
и даже если соотв. функции доступны, работают они не всегда.

Функция-индикатор вызывается с нужными параметрами в соотв. 
replacement-функции в payload module. Если вернёт true - нужно симулировать 
failure соотв. целевой функции, если true - просто вызвать целевую функцию 
с нужными параметрами и не вмешиваться.

Если для данной целевой функции функция-индикатор не задана - fault 
simulation для этой целевой функции не проводим.

[??]"Сценарий" fault simulation - набор индексов функций-индикаторов для 
интересующих целевых функций.

[??]
Какие именно параметры должна принимать функция-индикатор? 
Может, const void* data - а интерпретирует пусть сама? В принципе, 
функция-индикатор и соотв. replacement-функция, которая её вызывает, должны 
быть так и так согласованы друг с другом. Так что согласовать, что именно 
передаётся через параметр 'data', будет несложно.

=======================================================================

3. Механизм сбора данных, replacement-функции

3.1
Исходный код replacement-функции для стандартных типов payload module (Call 
Monitor, Fault Simulator, Base Checker), вероятно, стоит генерировать 
автоматически по их более наглядному описанию. 

Для Call Monitor и др. типов payload-модулей, использующих trace events,
можно и соотв. TRACE_EVENT-объявления таким же образом создавать.

Идеи чем-то похожи на то, что есть в T2C: разработчик системы (тестов, в 
случае T2C) задаёт логику её работы на понятном ему языке, а полный 
исходный код соотв. системы создаётся автоматически по спец. шаблонам. 
Детали реализации скрыты от разработчика системы в этих шаблонах и соотв. 
API. 

Разработчику ни к чему разбираться, как именно надо объявить trace events 
или вызвать функцию-индикатор при fault simulation (см. 2.4). Он 
концентрируется на коде, реализующем логику работы системы.

[NB] Такой подход, кстати, может нам сильно упростить перенос приложений, 
разработанных на базе KEDR, на новые версии KEDR. Шаблоны изменятся, а 
логику, возможно, если и придётся менять, но не слишком сильно (аналогия с 
переносом тестовых наборов с T2C v1 на T2C v2).

3.2
Один из примеров replacement-функции для payload module типа "Call Monitor" 
(см. пример "call_repl_with_events"):

-----------
long 
repl_copy_from_user(void* to, const void __user * from, unsigned long n)
{
	long result = copy_from_user(to, from, n);
	
	/* Here is our tracepoint for this function */
	trace_called_copy_from_user(to, from, n, result);
	
	return result;
}
-----------

Если несколько обобщить, примерная структура подобных функций м.б. такой 
(в формате, наподобие MiST Engine templates):

----- <$repl_function$> ------
<$ret_type$>
repl_<$target_func_name$>(<$target_param_spec : join(,)$>)
{
# Здесь сохраним возвращаемое значение целевой функции. 
# Для простоты, не рассм. тут случай, когда она ничего не возвращает.
    <$ret_type$> result;

# Тут вставляется заданный разработчиком кусок кода - как есть.
# Может пригодиться для получения значений каких-то системных 
# параметров и пр.
    <$prologue_code$> 

# Вызываем целевую функцию, сохраняем возвращаемое значение.
    result = <$target_func_name$>(<$target_param : join(,)$>);
    
# Тут вставляется заданный разработчиком кусок кода - как есть.
# Может пригодиться для какой-то предварительной обработки результатов 
# вызова целевой функции и пр. Полученные данные потом, вероятно, будут 
# переданы в соотв. trace event.
    <$epilogue_code$> 

# Trace event - выдача результатов для послед. анализа в use space.
    trace_called_<$target_func_name$>(<$trace_event_param : join(,)$>);

# Конец
    return result;
}
-----------
----- <$target_param_spec$> ------
<$target_param_type$> <$target_param$>
-----------

Параметры: ret_type, target_func_name, target_param_type, target_param, 
trace_event_param, prologue_code, epilogue_code.

Эти параметры поступают от пользователя, из пользовательского представления 
логики сбора информации. Это представление может быть просто набором 
записей след. вида (а может и как-то по-другому выглядеть, главное, чтобы 
наглядно для пользователя это было):

---------------------------------------
target_func_name =  copy_from_user

ret_type =          long

target_param_type = void*
target_param =      to

target_param_type = const void __user * 
target_param =      from

target_param_type = unsigned long
target_param =      n

prologue_code =>>
/* no-op */
<<

epilogue_code =>>
/* no-op */
<<

trace_event_param = to
trace_event_param = from
trace_event_param = n
trace_event_param = result
trace_event_param = whatever_else
---------------------------------------
[NB] Параметры trace event не обязаны совпадать с параметрами целевой 
функции. В trace event можно передавать что угодно.

[NB] В дальнейшем, вероятно, будет полезно разработать хоть несложный GUI 
и/или CUI для задания необходимых значений параметров.

Каким-то подобным образом и в других типах payload module можно всё 
организовать (разные наборы шаблонов + MiST Engine?).

MiST Engine для template-based generation здесь не пригодится ли?
Очень даже пригодится. Правда, за раз MiST Engine может сгенерировать
только одну replacement-функцию: чтобы создать их список за раз, нужна была
бы поддержка partial join, которой в MiST Engine сейчас нет. Т.е. join не
по всем значениям, скажем, параметра 'trace_event_param', а только по тем,
которые относятся к данной replacement-функции. Такое пока невозможно. Но
можно вызывать MiST Engine не один раз, а больше. Каждая replacement-
функция генерируется соотв. вызовом MiST Engine, а полученная строка
добавляется к значениям, скажем, атрибута 'replacement_function'. Затем 
MiST Engine вызывается ещё раз, уже для шаблона соотв. source-файла 
целиком, где и производится join значений 'replacement_function'.

[NB] Это лучше делать в программе на С, а не вызывая mist_engine command 
line tool. Программе понадобится libmist_engine.so (статически лучше не 
линковать, надо ориентироваться только на public MiST Engine API). Эту 
библиотеку удобно держать вместе с данной программой, не делать доступной 
всей системе. $ORIGIN тут поможет.
=======================================================================

4. API для пользовательского режима

4.1
API для пользовательского режима можно реализовать, например, в библиотеке 
(статической или динамической - можно и просто набор .c и .h файлов с 
реализацией API предоставить) и соотв. command line tool. Библиотека - для 
использования в программах на С/С++, command line tool - для использования 
в скриптовых языках (shell, perl, ...) и пр.

4.2
В KEDR API инкапсулирован механизм работы с модулями KEDR в ядре, механизм 
получения данных, собранных этими модулями и пр. 

Как именно происходит обмен данными и управление системой KEDR (передача 
сценариев fault simulation и т.д.) - вопрос реализации API, от пользователя 
это скрыто.

4.3
Если тест для данного target module написан на скриптовом языке, этот тест 
может читать данные из trace и trace_pipe непосредственно. Пусть тест 
рarse'ит считанные записи и оперирует с полученными данными, как ему угодно.

[NB] Формат каждой записи доступен в одном из файлов в каталоге, соотв. 
нужному событию, - на случай, если вдруг понадобится.

Тесты на С/С++ и т.д. тоже могут так делать. Правда, в тестах на "чистом" С 
не очень удобно каждый раз реализовывать разбор считанных из трассы 
записей. Для удобства для таких тестов можно реализовать относительно 
несложный API для выполнения след. операций:

- Установить callback-функцию на событие данного типа (или, что то же 
самое, на вызов данной целевой функции) - она будет вызываться каждый раз, 
когда в трассе появится событие соотв. типа. В аргументах своих эта 
callback-функция получит как-то аргументы соотв. trace event'а.

- Начать наблюдение за трассой.

- Закончить наблюдение за трассой (когда именно закончить наблюдение за 
трассой, - пусть тест сам решает).

[??] Callback может получать в качестве параметров, например, список 
структур {имя, variant}. "Имя" - имя параметра, "variant" - значение 
параметра в виде структуры a la QVariant в Qt. Это даст возможность 
унифицировать сигнатуру callback'ов. Ведь функция, которая будет эти 
callback'и вызывать, должна знать все необх. их сигнатуры ещё на этапе 
компиляции. Правда, использовать не всегда удобно будет.

Теоретически, можно попробовать реализовать callback'и, которые получают 
ровно те же параметры, что выводят соотв. trace events. Было бы очень 
удобно. Для этого необходимо как-то сгенерировать код своеобразной 
dispatch-функции, которая должна определить, к какому типу относится 
текущая запись о событии, декодировать нужные параметры (что-то вроде 
sscanf по формату вывода?) и вызвать callback-функцию, заданную для данного 
типа события, с этими параметрами. Как хранить соответствие <тип события> - 
<callback>, непонятно. Тем более, что у callback-функций для разных типов 
событий м.б. разные сигнатуры.

=======================================================================

99. Разное

Debugfs можно монтировать туда, куда нам удобнее. Неважно, что при этом эта 
файловая система ещё куда-то м.б. смонтирована (/debug/, /sys/kernel/debug/ 
или куда угодно).
=======================================================================
